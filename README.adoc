---
tags: [hadoop,yarn,boot,batch]
projects: [spring-hadoop]
---
:spring_version: 4.0.3.RELEASE
:spring_boot_version: 1.0.0.RELEASE
:spring_hadoop_version: 2.0.0.RC2
:java_version: 1.6
:Component: http://docs.spring.io/spring/docs/{spring_version}/javadoc-api/org/springframework/stereotype/Component.html
:SpringComponentScanAnnotation: http://docs.spring.io/spring/docs/{spring_version}/javadoc-api/org/springframework/context/annotation/ComponentScan.html
:SpringConfigurationAnnotation: http://docs.spring.io/spring/docs/{spring_version}/javadoc-api/org/springframework/context/annotation/Configuration.html
:SpringBeanAnnotation: http://docs.spring.io/spring/docs/{spring_version}/javadoc-api/org/springframework/context/annotation/Bean.html
:SpringApplication: http://docs.spring.io/spring-boot/docs/{spring_boot_version}/api/org/springframework/boot/SpringApplication.html
:ConfigurationProperties: http://docs.spring.io/spring-boot/docs/{spring_boot_version}/api/org/springframework/boot/context/properties/ConfigurationProperties.html
:EnableAutoConfiguration: http://docs.spring.io/spring-boot/docs/{spring_boot_version}/api/org/springframework/boot/autoconfigure/EnableAutoConfiguration.html
:YarnClient: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/client/YarnClient.html
:YarnAppmaster: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/am/YarnAppmaster.html
:YarnContainer: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/container/YarnContainer.html
:YarnContainerAnnotation: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/annotation/YarnContainer.html
:OnYarnContainerStartAnnotation: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/annotation/OnYarnContainerStart.html
:SpringYarnBootApplication: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/boot/app/SpringYarnBootApplication.html
:DefaultYarnContainer: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/yarn/container/DefaultYarnContainer.html
:FsShell: http://docs.spring.io/spring-hadoop/docs/{spring_hadoop_version}/api/org/springframework/data/hadoop/fs/FsShell.html
:toc:
:icons: font
:source-highlighter: prettify
:project_id: gs-yarn-batch-processing
:yarn_base_appmaster: gs-yarn-batch-processing-appmaster
:yarn_base_container: gs-yarn-batch-processing-container
:yarn_base_client: gs-yarn-batch-processing-client
:yarn_base_dist: gs-yarn-batch-processing-dist
This guide walks you through the process of executing a Spring Batch job on Hadoop YARN.

== What you'll build

You'll build a simple Hadoop YARN application with Spring Hadoop,
Spring Batch and Spring Boot.

== What you'll need

include::https://raw.github.com/spring-guides/getting-started-macros/master/prereq_editor_jdk_buildtools.adoc[]
 - Local single-node instance based on Hadoop 2.2.0 or later

NOTE: Testing this sample application don't need existing or running Hadoop instance.

include::https://raw.github.com/spring-guides/getting-started-macros/master/how_to_complete_this_guide.adoc[]

[[scratch]]
== Set up the project

First you set up a basic build script. You can use any build system you like when building apps with Spring, but the code you need to work with http://gradle.org[Gradle] is included here. If you're not familiar with it, refer to link:/guides/gs/gradle[Building Java Projects with Gradle].

include::https://raw.github.com/spring-guides/getting-started-macros/master/create_directory_structure_yarn_test_hello.adoc[]

=== Create a Gradle build file
Below is the https://github.com/spring-guides/{project_id}/blob/master/initial/build.gradle[initial Gradle build file]. If you are using link:/guides/gs/sts[Spring Tool Suite (STS)], you can import the guide directly.

`build.gradle`
[source,java]
----
include::complete/build.gradle[]
----

In above gradle build file we simply create three different jars, each having classes for its specific role. These jars are then repackaged by Spring Boot's gradle plugin to create an executable jars.

== Spring Batch Intro

Many batch processing problems can be solved with single threaded,
single process jobs, so it is always a good idea to properly check if
that meets your needs before thinking about more complex
implementations. When you are ready to start implementing a job with
some parallel processing, Spring Batch offers a range of options. At a
high level there are two modes of parallel processing: single process,
multi-threaded; and multi-process.

Spring Hadoop contains a support for running Spring Batch jobs on a
Hadoop cluster. For better parallel processing Spring Batch
partitioned steps can be executed on a Hadoop cluster as remote steps.

Starting point running a Spring Batch Job is always the Application
Master whether a job is just simple job with or without partitioning.
In case partitioning is not used the whole job would be run within the
Application Master and no Containers would be launched. This may seem
a bit odd to run something on Hadoop without using Containers but one
should remember that Application Master is also just a resource
allocated from a Hadoop cluster.

Order to run Spring Batch jobs on a Hadoop cluster, few constraints
exists:

- `Job Context` - Application Master is the main entry point of running
the job.
- `Job Repository` - Application Master needs to have access to a
repository which is located either in-memory or in a database. These
are the two type natively supported by Spring Batch.
- `Remote Steps` - Due to nature how Spring Batch partitioning works,
remote step needs an access to a job repository.

Let's take a quick look how Spring Batch partitioning is handled.
Concept of running a partitioned job involves three things, Remote
steps, Partition Handler and a Partitioner. If we do a little bit of
oversimplification a remote step is like any other step from a user
point of view. Spring Batch itself does not contain implementations
for any proprietary grid or remoting fabrics. Spring Batch does
however provide a useful implementation of PartitionHandler that
executes Steps locally in separate threads of execution, using the
TaskExecutor strategy from Spring. Spring Hadoop provides
implementation to execute Steps remotely on a Hadoop cluster.

NOTE: For more background information about the Spring Batch
Partitioning, read the Spring Batch reference documentation.

[[initial]]
== Create a Remote Batch Step

Here you create a `PrintTasklet` class.

`gs-yarn-batch-processing-container/src/main/java/hello/container/PrintTasklet.java`
[source,java]
----
include::complete/gs-yarn-batch-processing-container/src/main/java/hello/container/PrintTasklet.java[]
----

`Tasklet` in Spring Batch is one of the easiest concepts to use when
something needs to be executed in part of a job and step processing.
This is serving a purpose of demonstrating how simple it is to execute
a real `Partitioned Step`s on Hadoop YARN without introducing more
complex job processing.

In above `PrintTasklet` we simply write a log message when `Tasklet`
itself is executed.

Here you create a `ContainerApplication` class.

`gs-yarn-batch-processing-container/src/main/java/hello/container/ContainerApplication.java`
[source,java]
----
include::complete/gs-yarn-batch-processing-container/src/main/java/hello/container/ContainerApplication.java[]
----

- `@EnableYarnRemoteBatchProcessing` tells Spring to enable Batch
  processing on YARN Containers. Batch `@EnableBatchProcessing` is
  automatically included meaning all builders for JavaConfig are
  available.
- We `@AutoWired` step builder which is then used to create steps as
  beans.
- We defined `PrintTasklet` as `@Bean`
- We created a step as `@Bean` and instructed it to execute a tasklet.

== Create a Batch Job

Here you create a `AppmasterApplication` class.

`gs-yarn-batch-processing-appmaster/src/main/java/hello/appmaster/AppmasterApplication.java`
[source,java]
----
include::complete/gs-yarn-batch-processing-appmaster/src/main/java/hello/appmaster/AppmasterApplication.java[]
----

- `@EnableYarnBatchProcessing` tells Spring to enable Batch processing
  on appmaster. 
- We `@AutoWired` builders for steps and jobs.


== Create a Yarn Client

Here you create a `ClientApplication` class.

`gs-yarn-batch-processing-client/src/main/java/hello/client/ClientApplication.java`
[source,java]
----
include::complete/gs-yarn-batch-processing-client/src/main/java/hello/client/ClientApplication.java[]
----

`ClientApplication` is similar what we've used in other examples and
its only purpose is to submit an application.

include::https://raw.github.com/spring-guides/getting-started-macros/master/build_yarn_application.adoc[]

== Run the Application

Now that you've successfully compiled and packaged your application,
it's time to do the fun part and execute it on a Hadoop YARN.

Simply run your executable client jar.

[source]
----
$ cd gs-yarn-batch-processing-dist
$ java -jar target/gs-yarn-batch-processing-dist/gs-yarn-batch-processing-client-0.1.0.jar
----

If application executes successfully you should be able to see two steps executed on a YARN.

== Create a JUnit Test Class

Below is a class which can be used to execute this application as a
JUnit test without running Hadoop cluster.

`gs-yarn-batch-processing-dist/src/test/java/hello/AppTests.java`
[source,java]
----
include::complete/gs-yarn-batch-processing-dist/src/test/java/hello/AppIT.java[]
----

== Summary

Congratulations! You've just developed a Spring YARN application
executing a Spring Batch job! 
